{"name":"Leech","body":"Leech\r\n=====\r\n\r\nCrawling capabilities for Apache Tika. Crawl content out of e.g. file systems, http(s) sources (webcrawling) or imap(s) servers. Leech offers additional Tika parsers providing crawling capabilities.  \r\nIt is the RDF free successor of Aperture from the DFKI GmbH Knowledge Management group and available unter the terms of the [GPLv3](http://www.gnu.org/licenses/gpl.html). In the case you need a different license or want to make a project with us, feel free to [contact us](https://github.com/leechcrawler/leech/blob/master/people.md)!\r\n\r\nThe key intentions of Leech:\r\n* Ease of use - crawl a data source with a few lines of code.\r\n* Low learning curve - Leech integrates seamlessly into the Tika world.\r\n* Extensibility - write your own crawlers, support new data source protocols and plug them in by simply adding your jar into the classpath.\r\n* All parsing capabilities from Apache Tika are supported, including your own parsers.\r\n* Incremental crawling, offered for existing and new crawlers.\r\n\r\n***\r\n[How to start](https://github.com/leechcrawler/leech/blob/master/how2start.md) | [Code snippets / Examples](https://github.com/leechcrawler/leech/blob/master/codeSnippets.md) | [Extending Leech](https://github.com/leechcrawler/leech/blob/master/extending.md) | [Mailing list](https://github.com/leechcrawler/leech/blob/master/mailinglist.md) | [People / Contact] (https://github.com/leechcrawler/leech/blob/master/people.md) | [Supporters](https://github.com/leechcrawler/leech/blob/master/supporters.md)\r\n***\r\nCrawl something incrementally in 1 minute:\r\n\r\n    String strSourceUrl = \"URL4FileOrDirOrWebsiteOrImapfolderOrImapmessageOrSomething\";\r\n\r\n    Leech leech = new Leech();\r\n    CrawlerContext crawlerContext = new CrawlerContext();\r\n    crawlerContext.setIncrementalCrawlingHistoryPath(\"./history/4SourceUrl\");\r\n    leech.parse(strSourceUrl, new DataSinkContentHandlerAdapter()\r\n    {\r\n        public void processNewData(Metadata metadata, String strFulltext)\r\n        {\r\n            System.out.println(\"Extracted metadata:\\n\" + metadata + \"\\nExtracted fulltext:\\n\" + strFulltext);\r\n        }\r\n        public void processModifiedData(Metadata metadata, String strFulltext)\r\n        {\r\n        }\r\n        public void processRemovedData(Metadata metadata)\r\n        {\r\n        }\r\n        public void processErrorData(Metadata metadata)\r\n        {\r\n        }\r\n    }, crawlerContext.createParseContext());\r\n","tagline":"Crawling capabilities for Apache Tika","google":"UA-32092115-1","note":"Don't delete this file! It's used internally to help with page regeneration."}