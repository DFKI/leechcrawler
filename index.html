<!doctype html>
<!-- The Time Machine GitHub pages theme was designed and developed by Jon Rohan, on Feb 7, 2012. -->
<!-- Follow him for fun. http://twitter.com/jonrohan. Tail his code on http://github.com/jonrohan -->
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <link rel="stylesheet" href="stylesheets/stylesheet.css" media="screen"/>
  <link rel="stylesheet" href="stylesheets/pygment_trac.css"/>
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
  <script type="text/javascript" src="javascripts/script.js"></script>

  <title>Leech</title>
  <meta name="description" content="Crawling capabilities for Apache Tika">

  <meta name="viewport" content="width=device-width,initial-scale=1">

</head>

<body>

  <div class="wrapper">
    <header>
      <h1 class="title">Leech</h1>
    </header>
    <div id="container">
      <p class="tagline">Crawling capabilities for Apache Tika</p>
      <div id="main" role="main">
        <div class="download-bar">
        <div class="inner">
          <a href="https://github.com/leechcrawler/leech/tarball/master" class="download-button tar"><span>Download</span></a>
          <a href="https://github.com/leechcrawler/leech/zipball/master" class="download-button zip"><span>Download</span></a>
          <a href="https://github.com/leechcrawler/leech" class="code">View Leech on GitHub</a>
        </div>
        <span class="blc"></span><span class="trc"></span>
        </div>
        <article class="markdown-body">
          <h1>Leech</h1>

<p>Crawling capabilities for Apache Tika. Crawl content out of e.g. file systems, http(s) sources (webcrawling) or imap(s) servers. Leech offers additional Tika parsers providing these crawling capabilities.<br>
It is the RDF free successor of Aperture from the DFKI GmbH Knowledge Management group and available unter the terms of the <a href="http://www.gnu.org/licenses/gpl.html">GPLv3</a>. In the case you need a different license or want to make a project with us, feel free to <a href="https://github.com/leechcrawler/leech/blob/master/people.md">contact us</a>!</p>

<p>The key intentions of Leech:</p>

<ul>
<li>Ease of use - crawl a data source with a few lines of code.</li>
<li>Low learning curve - Leech integrates seamlessly into the Tika world.</li>
<li>Extensibility - write your own crawlers, support new data source protocols and plug them in by simply adding your jar into the classpath.</li>
<li>All parsing capabilities from Apache Tika are supported, including your own parsers.</li>
<li>Incremental crawling (second run crawls only the differences inside a data source, according to the last crawl). Offered for existing and new crawlers.</li>
</ul><hr><p><a href="https://github.com/leechcrawler/leech/blob/master/how2start.md">How to start</a> | <a href="https://github.com/leechcrawler/leech/blob/master/codeSnippets.md">Code snippets / Examples</a> | <a href="https://github.com/leechcrawler/leech/blob/master/extending.md">Extending Leech</a> | <a href="https://github.com/leechcrawler/leech/blob/master/mailinglist.md">Mailing list</a> | <a href="https://github.com/leechcrawler/leech/blob/master/people.md">People / Contact</a> | <a href="https://github.com/leechcrawler/leech/blob/master/supporters.md">Supporters</a></p>

<hr><p>Crawl something incrementally in 1 minute:</p>

<pre><code>String strSourceUrl = "URL4FileOrDirOrWebsiteOrImapfolderOrImapmessageOrSomething";

Leech leech = new Leech();
CrawlerContext crawlerContext = new CrawlerContext();
crawlerContext.setIncrementalCrawlingHistoryPath("./history/4SourceUrl");
leech.parse(strSourceUrl, new DataSinkContentHandlerAdapter()
{
    public void processNewData(Metadata metadata, String strFulltext)
    {
        System.out.println("Extracted metadata:\n" + metadata + "\nExtracted fulltext:\n" + strFulltext);
    }
    public void processModifiedData(Metadata metadata, String strFulltext)
    {
    }
    public void processRemovedData(Metadata metadata)
    {
    }
    public void processErrorData(Metadata metadata)
    {
    }
}, crawlerContext.createParseContext());
</code></pre>
        </article>
      </div>
    </div>
    <footer>
      <div class="owner">
      <p><a href="https://github.com/leechcrawler" class="avatar"><img src="https://secure.gravatar.com/avatar/2ab80ec54866b6951b9a13f71fa8d05d?s=30&amp;d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-user-420.png" width="48" height="48"/></a> <a href="https://github.com/leechcrawler">leechcrawler</a> maintains <a href="https://github.com/leechcrawler/leech">Leech</a></p>


      </div>
      <div class="creds">
        <small>This page generated using <a href="https://pages.github.com/">GitHub Pages</a><br/>theme by <a href="http://twitter.com/jonrohan/">Jon Rohan</a></small>
      </div>
    </footer>
  </div>
  <div class="current-section">
    <a href="#top">Scroll to top</a>
    <a href="https://github.com/leechcrawler/leech/tarball/master" class="tar">tar</a><a href="https://github.com/leechcrawler/leech/zipball/master" class="zip">zip</a><a href="" class="code">source code</a>
    <p class="name"></p>
  </div>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-32092115-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

</body>
</html>
