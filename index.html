<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Leech by leechcrawler</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Leech</h1>
        <p>Crawling capabilities for Apache Tika</p>
        <p class="view"><a href="https://github.com/leechcrawler/leech">View the Project on GitHub <small>leechcrawler/leech</small></a></p>
        <ul>
          <li><a href="https://github.com/leechcrawler/leech/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/leechcrawler/leech/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/leechcrawler/leech">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>Leech</h1>

<p>Crawling capabilities for Apache Tika. Crawl content out of e.g. file systems, http(s) sources (webcrawling) or imap(s) servers. Leech offers additional Tika parsers providing crawling capabilities.<br>
It is the RDF free successor of Aperture from the DFKI GmbH Knowledge Management group and available unter the terms of the <a href="http://www.gnu.org/licenses/gpl.html">GPLv3</a>. In the case you need a different license or want to make a project with us, feel free to <a href="https://github.com/leechcrawler/leech/blob/master/people.md">contact us</a>!</p>

<p>The key intentions of Leech:</p>

<ul>
<li>Ease of use - crawl a data source with a few lines of code.</li>
<li>Low learning curve - Leech integrates seamlessly into the Tika world.</li>
<li>Extensibility - write your own crawlers, support new data source protocols and plug them in by simply adding your jar into the classpath.</li>
<li>All parsing capabilities from Apache Tika are supported, including your own parsers.</li>
<li>Incremental crawling, offered for existing and new crawlers.</li>
</ul><hr><p><a href="https://github.com/leechcrawler/leech/blob/master/how2start.md">How to start</a> | <a href="https://github.com/leechcrawler/leech/blob/master/codeSnippets.md">Code snippets / Examples</a> | <a href="https://github.com/leechcrawler/leech/blob/master/extending.md">Extending Leech</a> | <a href="https://github.com/leechcrawler/leech/blob/master/mailinglist.md">Mailing list</a> | <a href="https://github.com/leechcrawler/leech/blob/master/people.md">People / Contact</a> | <a href="https://github.com/leechcrawler/leech/blob/master/supporters.md">Supporters</a></p>

<hr><p>Crawl something incrementally in 1 minute:</p>

<pre><code>String strSourceUrl = "URL4FileOrDirOrWebsiteOrImapfolderOrImapmessageOrSomething";

Leech leech = new Leech();
CrawlerContext crawlerContext = new CrawlerContext();
crawlerContext.setIncrementalCrawlingHistoryPath("./history/4SourceUrl");
leech.parse(strSourceUrl, new DataSinkContentHandlerAdapter()
{
    public void processNewData(Metadata metadata, String strFulltext)
    {
        System.out.println("Extracted metadata:\n" + metadata + "\nExtracted fulltext:\n" + strFulltext);
    }
    public void processModifiedData(Metadata metadata, String strFulltext)
    {
    }
    public void processRemovedData(Metadata metadata)
    {
    }
    public void processErrorData(Metadata metadata)
    {
    }
}, crawlerContext.createParseContext());
</code></pre>
      </section>
    </div>
    <footer>
      <p>Project maintained by <a href="https://github.com/leechcrawler">leechcrawler</a></p>
      <p>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></p>
    </footer>
    <!--[if !IE]><script>fixScale(document);</script><!--<![endif]-->
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-32092115-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>